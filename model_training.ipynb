{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "- In this notebook I will train Yolo v9 model to detect PPE (Personal Protective Equipment), using [this existing dataset](https://www.kaggle.com/datasets/snehilsanyal/construction-site-safety-image-dataset-roboflow) from [Roboflow](https://universe.roboflow.com/)\n",
    "- In the [next notebook](https://www.kaggle.com/hinepo/yolov8-inference-for-red-zone-application) I will use this custom model to make inference on videos and post-process the results so they can be used in a Red Zone/Trespassing detection application\n",
    "- This notebook is a generic training pipeline that you can use to train any Yolo model for object detection task on any dataset (images/number of classes), as long as you provide the dataset in the correct folder structure accepted by Yolo and the annotations/labels in Yolo format\n",
    "- [Ultralytics - docs](https://docs.ultralytics.com/)\n",
    "- [Ultralytics - github](https://github.com/ultralytics/ultralytics)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CSS (Construction Site Safety) Dataset](https://www.kaggle.com/datasets/snehilsanyal/construction-site-safety-image-dataset-roboflow):\n",
    "\n",
    "- Labels in this dataset:\n",
    "    - 0: Hardhat\n",
    "    - 1: Mask\n",
    "    - 2: NO-Hardhat\n",
    "    - 3: NO-Mask\n",
    "    - 4: NO-Safety Vest\n",
    "    - 5: Person\n",
    "    - 6: Safety Cone\n",
    "    - 7: Safety Vest\n",
    "    - 8: Machinery\n",
    "    - 9: Vehicle\n",
    "\n",
    "\n",
    "- More info:\n",
    "    - Number of classes: 10\n",
    "    - Label Annotation: YOLO format (.txt)\n",
    "      - `[class_id, center_x, center_y, width, height]`\n",
    "      \n",
    "___      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yolo Dataset folder structure: the paths to these folders will be written to a YAML file that will be used by Yolo.\n",
    "\n",
    "```\n",
    "Custom dataset directory (root)\n",
    "    - train\n",
    "        - images (folder including all training images)\n",
    "        - labels (folder including all training labels)\n",
    "    - validation\n",
    "        - images (folder including all validation images)\n",
    "        - labels (folder including all validation labels)\n",
    "    - test\n",
    "        - images (folder including all test images)\n",
    "        - labels (folder including all test labels)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='orange'>If you like this notebook, don't forget to show your support with your upvote!</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installs/Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T16:02:59.209023Z",
     "iopub.status.busy": "2025-02-27T16:02:59.208713Z",
     "iopub.status.idle": "2025-02-27T16:03:09.219453Z",
     "shell.execute_reply": "2025-02-27T16:03:09.218389Z",
     "shell.execute_reply.started": "2025-02-27T16:02:59.208991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 92 ms, sys: 30.5 ms, total: 122 ms\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "! pip install ultralytics==8.1.29 -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T16:04:36.832026Z",
     "iopub.status.busy": "2025-02-27T16:04:36.831710Z",
     "iopub.status.idle": "2025-02-27T16:04:36.836678Z",
     "shell.execute_reply": "2025-02-27T16:04:36.835840Z",
     "shell.execute_reply.started": "2025-02-27T16:04:36.831989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.1.29\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "print(ultralytics.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T16:04:36.838453Z",
     "iopub.status.busy": "2025-02-27T16:04:36.838083Z",
     "iopub.status.idle": "2025-02-27T16:04:37.462569Z",
     "shell.execute_reply": "2025-02-27T16:04:37.461928Z",
     "shell.execute_reply.started": "2025-02-27T16:04:36.838402Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T16:04:37.463700Z",
     "iopub.status.busy": "2025-02-27T16:04:37.463469Z",
     "iopub.status.idle": "2025-02-27T16:04:39.913685Z",
     "shell.execute_reply": "2025-02-27T16:04:39.912725Z",
     "shell.execute_reply.started": "2025-02-27T16:04:37.463680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B disabled.\n"
     ]
    }
   ],
   "source": [
    "! wandb disabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFG\n",
    "\n",
    "- CFG class enables easy and organized experimentation\n",
    "- Set `DEBUG = True` to make quick experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T16:04:39.915547Z",
     "iopub.status.busy": "2025-02-27T16:04:39.915175Z",
     "iopub.status.idle": "2025-02-27T16:04:39.921898Z",
     "shell.execute_reply": "2025-02-27T16:04:39.921082Z",
     "shell.execute_reply.started": "2025-02-27T16:04:39.915516Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DEBUG = False\n",
    "    FRACTION = 0.05 if DEBUG else 1.0\n",
    "    SEED = 88\n",
    "\n",
    "    # classes\n",
    "    CLASSES = ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask',\n",
    "               'NO-Safety Vest', 'Person', 'Safety Cone',\n",
    "               'Safety Vest', 'machinery', 'vehicle']\n",
    "    NUM_CLASSES_TO_TRAIN = len(CLASSES)\n",
    "\n",
    "    # training\n",
    "    EPOCHS = 3 if DEBUG else 50 # 100\n",
    "    BATCH_SIZE = 16\n",
    "    \n",
    "    BASE_MODEL = 'yolov8s' # yolov8n, yolov8s, yolov8m, yolov8l, yolov8x\n",
    "    BASE_MODEL_WEIGHTS = f'{BASE_MODEL}.pt'\n",
    "    EXP_NAME = f'ppe_css_{EPOCHS}_epochs'\n",
    "    \n",
    "    OPTIMIZER = 'auto' # SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto\n",
    "    LR = 1e-3\n",
    "    LR_FACTOR = 0.01\n",
    "    WEIGHT_DECAY = 5e-4\n",
    "    DROPOUT = 0.0\n",
    "    PATIENCE = 20\n",
    "    PROFILE = False\n",
    "    LABEL_SMOOTHING = 0.0    \n",
    "\n",
    "    # paths\n",
    "    CUSTOM_DATASET_DIR = '/kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/'\n",
    "    OUTPUT_DIR = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create YAML file\n",
    "\n",
    "- Create ```data.yaml``` file properly formatted to be used by Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T16:04:42.535211Z",
     "iopub.status.busy": "2025-02-27T16:04:42.534868Z",
     "iopub.status.idle": "2025-02-27T16:04:42.542763Z",
     "shell.execute_reply": "2025-02-27T16:04:42.541727Z",
     "shell.execute_reply.started": "2025-02-27T16:04:42.535184Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_file = {\n",
    "    'train': os.path.join(CFG.CUSTOM_DATASET_DIR, 'train'),\n",
    "    'val': os.path.join(CFG.CUSTOM_DATASET_DIR, 'valid'),\n",
    "    'test': os.path.join(CFG.CUSTOM_DATASET_DIR, 'test'),\n",
    "    'nc': CFG.NUM_CLASSES_TO_TRAIN,\n",
    "    'names': CFG.CLASSES\n",
    "    }\n",
    "\n",
    "with open(os.path.join(CFG.OUTPUT_DIR, 'data.yaml'), 'w+') as file:\n",
    "    yaml.dump(dict_file, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T16:04:42.820026Z",
     "iopub.status.busy": "2025-02-27T16:04:42.819760Z",
     "iopub.status.idle": "2025-02-27T16:04:42.828799Z",
     "shell.execute_reply": "2025-02-27T16:04:42.827950Z",
     "shell.execute_reply.started": "2025-02-27T16:04:42.819996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      "- Hardhat\n",
      "- Mask\n",
      "- NO-Hardhat\n",
      "- NO-Mask\n",
      "- NO-Safety Vest\n",
      "- Person\n",
      "- Safety Cone\n",
      "- Safety Vest\n",
      "- machinery\n",
      "- vehicle\n",
      "nc: 10\n",
      "test: /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/test\n",
      "train: /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/train\n",
      "val: /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/valid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### read yaml file created\n",
    "def read_yaml_file(file_path = CFG.CUSTOM_DATASET_DIR):\n",
    "    with open(file_path, 'r') as file:\n",
    "        try:\n",
    "            data = yaml.safe_load(file)\n",
    "            return data\n",
    "        except yaml.YAMLError as e:\n",
    "            print(\"Error reading YAML:\", e)\n",
    "            return None\n",
    "\n",
    "### print it with newlines\n",
    "def print_yaml_data(data):\n",
    "    formatted_yaml = yaml.dump(data, default_style=False)\n",
    "    print(formatted_yaml)\n",
    "\n",
    "file_path = os.path.join(CFG.OUTPUT_DIR, 'data.yaml')\n",
    "yaml_data = read_yaml_file(file_path)\n",
    "\n",
    "if yaml_data:\n",
    "    print_yaml_data(yaml_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "- Check some images\n",
    "- Image utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, print_info = True, hide_axis = False):\n",
    "    if isinstance(image, str):  # Check if it's a file path\n",
    "        img = Image.open(image)\n",
    "        plt.imshow(img)\n",
    "    elif isinstance(image, np.ndarray):  # Check if it's a NumPy array\n",
    "        image = image[..., ::-1]  # BGR to RGB\n",
    "        img = Image.fromarray(image)\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported image format\")\n",
    "\n",
    "    if print_info:\n",
    "        print('Type: ', type(img), '\\n')\n",
    "        print('Shape: ', np.array(img).shape, '\\n')\n",
    "\n",
    "    if hide_axis:\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image_path = '/kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/train/images/-2297-_png_jpg.rf.9fff3740d864fbec9cda50d783ad805e.jpg'\n",
    "display_image(example_image_path, print_info = True, hide_axis = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize many images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_images_from_folder(folder_path, num_images=20, seed=CFG.SEED):\n",
    "    \n",
    "    random.seed(seed)\n",
    "\n",
    "    # Get a list of image files in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.jpeg', '.gif'))]\n",
    "\n",
    "    # Ensure that we have at least num_images files to choose from\n",
    "    if len(image_files) < num_images:\n",
    "        raise ValueError(\"Not enough images in the folder\")\n",
    "\n",
    "    # Randomly select num_images image files\n",
    "    selected_files = random.sample(image_files, num_images)\n",
    "\n",
    "    # Create a subplot grid\n",
    "    num_cols = 5\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "\n",
    "    for i, file_name in enumerate(selected_files):\n",
    "        # Open and display the image using PIL\n",
    "        img = Image.open(os.path.join(folder_path, file_name))\n",
    "        \n",
    "        if num_rows == 1:\n",
    "            ax = axes[i % num_cols]\n",
    "        else:\n",
    "            ax = axes[i // num_cols, i % num_cols]\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        # ax.set_title(file_name)\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for i in range(num_images, num_rows * num_cols):\n",
    "        if num_rows == 1:\n",
    "            fig.delaxes(axes[i % num_cols])\n",
    "        else:\n",
    "            fig.delaxes(axes[i // num_cols, i % num_cols])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = CFG.CUSTOM_DATASET_DIR + 'train/images/'\n",
    "plot_random_images_from_folder(folder_path, num_images=20, seed=CFG.SEED)\n",
    "# plot_random_images_from_folder(folder_path, num_images=20, seed=54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_properties(image_path):\n",
    "    # Read the image file\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Check if the image file is read successfully\n",
    "    if img is None:\n",
    "        raise ValueError(\"Could not read image file\")\n",
    "\n",
    "    # Get image properties\n",
    "    properties = {\n",
    "        \"width\": img.shape[1],\n",
    "        \"height\": img.shape[0],\n",
    "        \"channels\": img.shape[2] if len(img.shape) == 3 else 1,\n",
    "        \"dtype\": img.dtype,\n",
    "    }\n",
    "\n",
    "    return properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_properties = get_image_properties(example_image_path)\n",
    "img_properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "class_idx = {str(i): CFG.CLASSES[i] for i in range(CFG.NUM_CLASSES_TO_TRAIN)}\n",
    "\n",
    "class_stat = {}\n",
    "data_len = {}\n",
    "class_info = []\n",
    "\n",
    "for mode in ['train', 'valid', 'test']:\n",
    "    class_count = {CFG.CLASSES[i]: 0 for i in range(CFG.NUM_CLASSES_TO_TRAIN)}\n",
    "\n",
    "    path = os.path.join(CFG.CUSTOM_DATASET_DIR, mode, 'labels')\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        with open(os.path.join(path, file)) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "            for cls in set([line[0] for line in lines]):\n",
    "                class_count[class_idx[cls]] += 1\n",
    "\n",
    "    data_len[mode] = len(os.listdir(path))\n",
    "    class_stat[mode] = class_count\n",
    "\n",
    "    class_info.append({'Mode': mode, **class_count, 'Data_Volume': data_len[mode]})\n",
    "\n",
    "dataset_stats_df = pd.DataFrame(class_info)\n",
    "dataset_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with 1 row and 3 columns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot vertical bar plots for each mode in subplots\n",
    "for i, mode in enumerate(['train', 'valid', 'test']):\n",
    "    sns.barplot(\n",
    "        data=dataset_stats_df[dataset_stats_df['Mode'] == mode].drop(columns='Mode'),\n",
    "        orient='v',\n",
    "        ax=axes[i],\n",
    "        palette='Set2'\n",
    "    )\n",
    "    \n",
    "    axes[i].set_title(f'{mode.capitalize()} Class Statistics')\n",
    "    axes[i].set_xlabel('Classes')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].tick_params(axis='x', rotation=90) \n",
    "\n",
    "    # Add annotations on top of each bar\n",
    "    for p in axes[i].patches:\n",
    "        axes[i].annotate(f\"{int(p.get_height())}\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                         ha='center', va='center', fontsize=8, color='black', xytext=(0, 5),\n",
    "                         textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for mode in ['train', 'valid', 'test']:\n",
    "    print(f'\\nImage sizes in {mode} set:')\n",
    "\n",
    "    img_size = 0\n",
    "    for file in glob.glob(os.path.join(CFG.CUSTOM_DATASET_DIR, mode, 'images', '*')):\n",
    "\n",
    "        image = Image.open(file)\n",
    "\n",
    "        if image.size != img_size:\n",
    "            print(f'{image.size}')\n",
    "            img_size = image.size\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model Inference\n",
    "\n",
    "- Just checking the power of the pretrained model inference on the CSS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.BASE_MODEL_WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(CFG.BASE_MODEL_WEIGHTS)\n",
    "\n",
    "results = model.predict(\n",
    "    source = example_image_path,\n",
    "\n",
    "    classes = [0],\n",
    "    conf = 0.30,\n",
    "    device = [0,1], # inference with dual GPU\n",
    "    imgsz = (img_properties['height'], img_properties['width']),\n",
    "\n",
    "    save = True,\n",
    "    save_txt = True,\n",
    "    save_conf = True,\n",
    "    exist_ok = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check predictions with base model\n",
    "example_image_inference_output = example_image_path.split('/')[-1]\n",
    "display_image(f'/kaggle/working/runs/detect/predict/{example_image_inference_output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "[Arguments for training](https://docs.ultralytics.com/modes/train/#arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model: ', CFG.BASE_MODEL_WEIGHTS)\n",
    "print('Epochs: ', CFG.EPOCHS)\n",
    "print('Batch: ', CFG.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load pre-trained YOLO model\n",
    "model = YOLO(CFG.BASE_MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### train\n",
    "model.train(\n",
    "    data = os.path.join(CFG.OUTPUT_DIR, 'data.yaml'),\n",
    "\n",
    "    task = 'detect',\n",
    "\n",
    "    imgsz = (img_properties['height'], img_properties['width']),\n",
    "\n",
    "    epochs = CFG.EPOCHS,\n",
    "    batch = CFG.BATCH_SIZE,\n",
    "    optimizer = CFG.OPTIMIZER,\n",
    "    lr0 = CFG.LR,\n",
    "    lrf = CFG.LR_FACTOR,\n",
    "    weight_decay = CFG.WEIGHT_DECAY,\n",
    "    dropout = CFG.DROPOUT,\n",
    "    fraction = CFG.FRACTION,\n",
    "    patience = CFG.PATIENCE,\n",
    "    profile = CFG.PROFILE,\n",
    "    label_smoothing = CFG.LABEL_SMOOTHING,\n",
    "\n",
    "    name = f'{CFG.BASE_MODEL}_{CFG.EXP_NAME}',\n",
    "    seed = CFG.SEED,\n",
    "    \n",
    "    val = True,\n",
    "    amp = True,    \n",
    "    exist_ok = True,\n",
    "    resume = False,\n",
    "    device = [0,1], # 0\n",
    "    verbose = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Export the model\n",
    "model.export(\n",
    "    format = 'onnx', # openvino, onnx, engine, tflite\n",
    "    imgsz = (img_properties['height'], img_properties['width']),\n",
    "    half = False,\n",
    "    int8 = False,\n",
    "    simplify = False,\n",
    "    nms = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_paths = [\n",
    "    i for i in\n",
    "    glob.glob(f'{CFG.OUTPUT_DIR}runs/detect/{CFG.BASE_MODEL}_{CFG.EXP_NAME}/*.png') +\n",
    "    glob.glob(f'{CFG.OUTPUT_DIR}runs/detect/{CFG.BASE_MODEL}_{CFG.EXP_NAME}/*.jpg')\n",
    "    if 'batch' not in i\n",
    "]\n",
    "\n",
    "results_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in sorted(results_paths):\n",
    "    print(file)\n",
    "    display_image(file, print_info = False, hide_axis = True)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss\n",
    "\n",
    "- The loss function in YOLO consists of three main components: box loss, class loss (cls loss), and objectness loss (dfl loss).\n",
    "- The total loss in YOLO is a combination of these three components\n",
    "\n",
    "___\n",
    "\n",
    "**Box loss:**\n",
    "- The box loss measures how accurately the predicted bounding box coordinates match the ground truth bounding box.\n",
    "- Is typically computed using a regression loss, such as Mean Squared Error (MSE), between the predicted bounding box coordinates (center coordinates, width, and height) and the ground truth bounding box coordinates.\n",
    "\n",
    "___\n",
    "\n",
    "**Class loss (cls):**\n",
    "- The class loss measures how well the predicted class probabilities match the true class labels.\n",
    "- The class loss is usually computed using a categorical cross-entropy loss, which penalizes the difference between the predicted class probabilities and the true class labels.\n",
    "\n",
    "___\n",
    "\n",
    "**Objectness loss (dfl):**\n",
    "- Distribution Focal Loss\n",
    "- YOLO predicts an \"objectness\" score for each bounding box, indicating the presence of an object within the grid cell. This score helps filter out irrelevant bounding boxes.\n",
    "- The objectness loss is calculated based on the difference between the predicted objectness score and the ground truth objectness label. It penalizes the model for false positives and false negatives in predicting the presence of an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{CFG.OUTPUT_DIR}runs/detect/{CFG.BASE_MODEL}_{CFG.EXP_NAME}/results.csv')\n",
    "df = df.rename(columns=lambda x: x.replace(\" \", \"\"))\n",
    "df.to_csv(f'{CFG.OUTPUT_DIR}training_log_df.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*'*50)\n",
    "print('\\nBest Training Box loss: ', df['train/box_loss'].min(), ', on epoch: ', df['train/box_loss'].argmin() + 1, '\\n')\n",
    "print('\\nBest Validation Box loss: ', df['val/box_loss'].min(), ', on epoch: ', df['val/box_loss'].argmin() + 1, '\\n')\n",
    "\n",
    "print('='*50)\n",
    "print('\\nBest Training Cls loss: ', df['train/cls_loss'].min(), ', on epoch: ', df['train/cls_loss'].argmin() + 1, '\\n')\n",
    "print('\\nBest Validation Cls loss: ', df['val/cls_loss'].min(), ', on epoch: ', df['val/cls_loss'].argmin() + 1, '\\n')\n",
    "\n",
    "print('='*50)\n",
    "print('\\nBest Training DFL loss: ', df['train/dfl_loss'].min(), ', on epoch: ', df['train/dfl_loss'].argmin() + 1, '\\n')\n",
    "print('\\nBest Validation DFL loss: ', df['val/dfl_loss'].min(), ', on epoch: ', df['val/dfl_loss'].argmin() + 1, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 15), sharex=True)\n",
    "\n",
    "### Training and Validation box_loss\n",
    "ax1.set_title('Box Loss')\n",
    "ax1.plot(df['epoch'], df['train/box_loss'], label='Training box_loss', marker='o', linestyle='-')\n",
    "ax1.plot(df['epoch'], df['val/box_loss'], label='Validation box_loss', marker='o', linestyle='-')\n",
    "ax1.set_ylabel('Box Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "### Training and Validation cls_loss\n",
    "ax2.set_title('Cls Loss')\n",
    "ax2.plot(df['epoch'], df['train/cls_loss'], label='Training cls_loss', marker='o', linestyle='-')\n",
    "ax2.plot(df['epoch'], df['val/cls_loss'], label='Validation cls_loss', marker='o', linestyle='-')\n",
    "ax2.set_ylabel('cls_loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "### Training and Validation dfl_loss\n",
    "ax3.set_title('DFL Loss')\n",
    "ax3.plot(df['epoch'], df['train/dfl_loss'], label='Training dfl_loss', marker='o', linestyle='-')\n",
    "ax3.plot(df['epoch'], df['val/dfl_loss'], label='Validation dfl_loss', marker='o', linestyle='-')\n",
    "ax3.set_xlabel('Epochs')\n",
    "ax3.set_ylabel('dfl_loss')\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "\n",
    "plt.suptitle('Training Metrics vs. Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results_paths = [\n",
    "    i for i in\n",
    "    glob.glob(f'{CFG.OUTPUT_DIR}runs/detect/{CFG.BASE_MODEL}_{CFG.EXP_NAME}/*.png') +\n",
    "    glob.glob(f'{CFG.OUTPUT_DIR}runs/detect/{CFG.BASE_MODEL}_{CFG.EXP_NAME}/*.jpg')\n",
    "    if 'val_batch' in i\n",
    "]\n",
    "\n",
    "len(validation_results_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(validation_results_paths) >= 1:\n",
    "    print(validation_results_paths[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check predictions or labels from a random validation batch\n",
    "if len(validation_results_paths) >= 1:\n",
    "    val_img_path = random.choice(validation_results_paths)\n",
    "    print(val_img_path)\n",
    "    display_image(val_img_path, print_info = False, hide_axis = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So now the model is trained and we have customized Yolo to detect PPE.\n",
    "- In my [next notebook](https://www.kaggle.com/hinepo/yolov8-inference-for-red-zone-application) I will use this model to make inference on a video, and combine the PPE detection with a Red Zone application.\n",
    "- **<font color='orange'>Upvote if you liked it!</font>**"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2919095,
     "sourceId": 5048288,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30554,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
